{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartpole_model(observation_space, action_space):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(observation_space, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, action_space),\n",
    "        nn.Softmax(dim=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(module):\n",
    "    if((type(module) == nn.Linear)):\n",
    "            nn.init.xavier_uniform_(module.weight.data)\n",
    "            module.bias.data.fill_(0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agents(num_agents, observation_space, action_space):\n",
    "    agents = []\n",
    "    \n",
    "    for _ in range(num_agents):\n",
    "        agent = cartpole_model(observation_space, action_space)\n",
    "        agent.apply(init_weight)\n",
    "        \n",
    "        for param in agent.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        agent.eval()\n",
    "        agents.append(agent)\n",
    "        \n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_agent(agent, env):\n",
    "    observation = env.reset()\n",
    "    \n",
    "    total_reward = 0\n",
    "    for _ in range(MAX_STEP):\n",
    "        observation = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
    "        action_probablity = agent(observation).detach().numpy()[0]\n",
    "        action = np.random.choice(range(env.action_space.n), 1, p=action_probablity).item()\n",
    "        next_observation, reward, terminal, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        observation = next_observation\n",
    "        \n",
    "        if terminal:\n",
    "            break\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_score(agent, env, runs):\n",
    "    score = 0\n",
    "    for _ in range(runs):\n",
    "        score += eval_agent(agent, env)\n",
    "        \n",
    "    return score/runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_agent_score(agents, env, runs):\n",
    "    agents_score = []\n",
    "    for agent in agents:\n",
    "        agents_score.append(agent_score(agent, env, runs))\n",
    "    \n",
    "    return agents_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(agent):\n",
    "    child_agent = copy.deepcopy(agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
